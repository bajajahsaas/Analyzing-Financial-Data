{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "crawlYahooFinance.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "BdOwvJngGoXs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import bs4 as bs\n",
        "import urllib.request\n",
        "import pandas as pd\n",
        "from time import sleep\n",
        "from lxml import html  \n",
        "import requests\n",
        "from time import sleep\n",
        "import json\n",
        "import argparse\n",
        "from collections import OrderedDict\n",
        "import lxml.html as lh\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LpC5ggz-twKQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def parse_url(url, cmp):\n",
        "  response = requests.get(url)\n",
        "  soup = bs.BeautifulSoup(response.text, 'lxml')\n",
        "  \n",
        "  listdf = []\n",
        "  \n",
        "  for table in soup.find_all('table'):\n",
        "    listdf.append(parse_html_table(table, cmp))\n",
        "  \n",
        "  return listdf\n",
        "    \n",
        "def parse_html_table(table, cmp):\n",
        "  n_columns = 0\n",
        "  n_rows=0\n",
        "  column_names = []\n",
        "\n",
        "  # Find number of rows and columns\n",
        "  # we also find the column titles if we can\n",
        "  for row in table.find_all('tr'):\n",
        "\n",
        "      # Determine the number of rows in the table\n",
        "      td_tags = row.find_all('td')\n",
        "      if len(td_tags) > 0:\n",
        "          n_rows+=1\n",
        "          if n_columns == 0:\n",
        "              # Set the number of columns for our table\n",
        "              n_columns = len(td_tags)\n",
        "\n",
        "      # Handle column names if we find them\n",
        "      th_tags = row.find_all('th') \n",
        "      if len(th_tags) > 0 and len(column_names) == 0:\n",
        "          for th in th_tags:\n",
        "              column_names.append(th.get_text().replace(cmp, \"cmp\"))\n",
        "  \n",
        "  # Safeguard on Column Titles\n",
        "  if len(column_names) > 0 and len(column_names) != n_columns:\n",
        "      raise Exception(\"Column titles do not match the number of columns\")\n",
        "\n",
        "  columns = column_names if len(column_names) > 0 else range(0,n_columns)\n",
        "  df = pd.DataFrame(columns = columns,\n",
        "                    index= range(0,n_rows))\n",
        "  row_marker = 0\n",
        "  for row in table.find_all('tr'):\n",
        "      column_marker = 0\n",
        "      columns = row.find_all('td')\n",
        "      for column in columns:\n",
        "          df.iat[row_marker,column_marker] = column.get_text()\n",
        "          column_marker += 1\n",
        "      if len(columns) > 0:\n",
        "          row_marker += 1\n",
        "\n",
        "  # Convert to float if possible\n",
        "  for col in df:\n",
        "      try:\n",
        "          df[col] = df[col].astype(float)\n",
        "      except ValueError:\n",
        "          pass\n",
        "\n",
        "  return df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NH3i7Qd6R03N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cmpList = ['TSLA', 'AAPL', 'NFLX', 'GM', 'F', 'FCAU', 'PCAR', 'MRK', 'PFE', 'JNJ', 'BMY', 'QCOM', 'MSFT' , 'ADBE', 'INTC', 'GOOGL', 'CRM', 'ORCL', 'IBM', 'FB', 'TWTR', 'AMZN', 'SCHW', 'ETFC', 'AMTD',]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fPodJIKYG2UA",
        "colab_type": "code",
        "outputId": "c5926cbe-a942-4298-8fdb-781f0be35a4a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "towriteCmpList = []\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('drive')\n",
        "\n",
        "#https://finance.yahoo.com/quote/%5EIXIC/components?p=%5EIXIC\n",
        "\n",
        "items = ['', '/analysis']\n",
        "urlPre = 'https://finance.yahoo.com/quote/'\n",
        "urlSuf = '?p='\n",
        "\n",
        "columns = None\n",
        "\n",
        "#scrappedData = getSummaryData(summaryUrl)\n",
        "# response = requests.get(financeUrl, verify=False)\n",
        "# soup = bs.BeautifulSoup(response.text)\n",
        "# print(soup.prettify())\n",
        "final_df = pd.DataFrame()\n",
        "\n",
        "for cmp in cmpList:\n",
        "  cmp_df_list = []\n",
        "  print('\\nCompany: ', cmp)\n",
        "  \n",
        "  for item in items:\n",
        "    url = urlPre + cmp + item + urlSuf + cmp\n",
        "    dataframe_list = parse_url(url, cmp)\n",
        "    \n",
        "    if item is '':\n",
        "      name = 'summary'\n",
        "    else:\n",
        "      name = item[1:len(item)]\n",
        "    \n",
        "    print(name, len(dataframe_list), 'tables')\n",
        "    \n",
        "    count = 1\n",
        "    \n",
        "    item_df = pd.DataFrame()\n",
        "    \n",
        "    for df in dataframe_list:\n",
        "    \n",
        "      # Summary (2), Analysis (6)\n",
        "      \n",
        "      if item is \"\":\n",
        "        df = df.transpose()\n",
        "        item_df = pd.concat([item_df, df], axis = 1, ignore_index = True)\n",
        "        \n",
        "        \n",
        "        \n",
        "      if item == '/analysis':\n",
        "        df.set_index(df.columns[0], inplace=True)\n",
        "        df = df.replace({pd.np.nan: None})\n",
        "        df = df.unstack().to_frame().sort_index(level=1).T\n",
        "        df.columns = df.columns.map(\"_\".join)\n",
        "        item_df = pd.concat([item_df, df], axis = 1)\n",
        "     \n",
        "    \n",
        "    if item is \"\":\n",
        "      new_header = item_df.iloc[0] #grab the first row for the header\n",
        "#       print(item_df)\n",
        "      item_df.columns = new_header #set the header row as the df header\n",
        "#       print(item_df)\n",
        "      item_df = item_df[1:] #take the data less the header row\n",
        "#       print(item_df)\n",
        "#       print(new_header)\n",
        "      item_df.reset_index(inplace=True, drop=True)\n",
        "     \n",
        "      \n",
        "    #print(item_df)\n",
        "    print(name, item_df.shape[1], 'Columns')\n",
        "    cmp_df_list.append(item_df)\n",
        "    \n",
        "#     filename = cmp + '_' + name + '.csv'\n",
        "#     item_df.to_csv(filename, index = False)\n",
        "#     !cp $filename drive/My\\ Drive/Isenberg/\n",
        "  \n",
        "  \n",
        "  \n",
        "  cmp_df = pd.DataFrame()\n",
        "  for df in cmp_df_list:\n",
        "    cmp_df = pd.concat([cmp_df,df], axis = 1)\n",
        "  \n",
        "  # Causes problem when company name is \"F\" and it gets replaced everywhere in the column names. Better to do in parse_url\n",
        "  # cmp_df.columns = cmp_df.columns.str.replace(cmp, \"cmp\")\n",
        "  \n",
        "  if columns == None:\n",
        "    columns = cmp_df.columns.tolist()\n",
        " \n",
        "  #cmp_df.sort_index(axis=1, inplace=True) # not required if string replace done at parsing time\n",
        "  \n",
        "  if (final_df.shape[0] != 0 and final_df.columns.equals(cmp_df.columns) == False ):\n",
        "    # except when final_df is empty. This should return always True. Else column mistmatch (ignore this company)\n",
        "    print('Column mismatch for company: ', cmp, ' Ignoring...')\n",
        "    continue\n",
        "    # MSFT: has current year (2020): typo\n",
        "    # ADBE: has different dates\n",
        "  else:\n",
        "    towriteCmpList.append(cmp)\n",
        "  \n",
        "  #print('intersections: ', cmp_df.columns.difference(final_df.columns).shape, final_df.columns.difference(cmp_df.columns).shape) #should always print 0\n",
        "  \n",
        "  final_df = pd.concat([final_df, cmp_df], ignore_index = True)\n",
        "\n",
        "final_df['company'] = towriteCmpList  \n",
        "final_df = final_df.set_index('company')\n",
        "print('Final Data: ',final_df.shape)\n",
        "\n",
        "filename = 'YahooData.xlsx'\n",
        "final_df.to_excel(filename)\n",
        "!cp $filename drive/My\\ Drive/Isenberg/"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at drive; to attempt to forcibly remount, call drive.mount(\"drive\", force_remount=True).\n",
            "\n",
            "Company:  TSLA\n",
            "summary 2 tables\n",
            "summary 16 Columns\n",
            "analysis 6 tables\n",
            "analysis 120 Columns\n",
            "intersections:  (120,) (0,)\n",
            "\n",
            "Company:  AAPL\n",
            "summary 2 tables\n",
            "summary 16 Columns\n",
            "analysis 6 tables\n",
            "analysis 120 Columns\n",
            "intersections:  (0,) (0,)\n",
            "\n",
            "Company:  NFLX\n",
            "summary 2 tables\n",
            "summary 16 Columns\n",
            "analysis 6 tables\n",
            "analysis 120 Columns\n",
            "intersections:  (0,) (0,)\n",
            "\n",
            "Company:  GM\n",
            "summary 2 tables\n",
            "summary 16 Columns\n",
            "analysis 6 tables\n",
            "analysis 120 Columns\n",
            "intersections:  (0,) (0,)\n",
            "\n",
            "Company:  F\n",
            "summary 2 tables\n",
            "summary 16 Columns\n",
            "analysis 6 tables\n",
            "analysis 120 Columns\n",
            "intersections:  (0,) (0,)\n",
            "\n",
            "Company:  FCAU\n",
            "summary 2 tables\n",
            "summary 16 Columns\n",
            "analysis 6 tables\n",
            "analysis 120 Columns\n",
            "intersections:  (0,) (0,)\n",
            "\n",
            "Company:  PCAR\n",
            "summary 2 tables\n",
            "summary 16 Columns\n",
            "analysis 6 tables\n",
            "analysis 120 Columns\n",
            "intersections:  (0,) (0,)\n",
            "\n",
            "Company:  MRK\n",
            "summary 2 tables\n",
            "summary 16 Columns\n",
            "analysis 6 tables\n",
            "analysis 120 Columns\n",
            "intersections:  (0,) (0,)\n",
            "\n",
            "Company:  PFE\n",
            "summary 2 tables\n",
            "summary 16 Columns\n",
            "analysis 6 tables\n",
            "analysis 120 Columns\n",
            "intersections:  (0,) (0,)\n",
            "\n",
            "Company:  JNJ\n",
            "summary 2 tables\n",
            "summary 16 Columns\n",
            "analysis 6 tables\n",
            "analysis 120 Columns\n",
            "intersections:  (0,) (0,)\n",
            "\n",
            "Company:  BMY\n",
            "summary 2 tables\n",
            "summary 16 Columns\n",
            "analysis 6 tables\n",
            "analysis 120 Columns\n",
            "intersections:  (0,) (0,)\n",
            "\n",
            "Company:  QCOM\n",
            "summary 2 tables\n",
            "summary 16 Columns\n",
            "analysis 6 tables\n",
            "analysis 120 Columns\n",
            "intersections:  (0,) (0,)\n",
            "\n",
            "Company:  MSFT\n",
            "summary 2 tables\n",
            "summary 16 Columns\n",
            "analysis 6 tables\n",
            "analysis 120 Columns\n",
            "Column mismatch for company:  MSFT  Ignoring...\n",
            "\n",
            "Company:  ADBE\n",
            "summary 2 tables\n",
            "summary 16 Columns\n",
            "analysis 6 tables\n",
            "analysis 120 Columns\n",
            "Column mismatch for company:  ADBE  Ignoring...\n",
            "\n",
            "Company:  INTC\n",
            "summary 2 tables\n",
            "summary 16 Columns\n",
            "analysis 6 tables\n",
            "analysis 120 Columns\n",
            "intersections:  (0,) (0,)\n",
            "\n",
            "Company:  GOOGL\n",
            "summary 2 tables\n",
            "summary 16 Columns\n",
            "analysis 6 tables\n",
            "analysis 120 Columns\n",
            "intersections:  (0,) (0,)\n",
            "\n",
            "Company:  CRM\n",
            "summary 2 tables\n",
            "summary 16 Columns\n",
            "analysis 6 tables\n",
            "analysis 120 Columns\n",
            "Column mismatch for company:  CRM  Ignoring...\n",
            "\n",
            "Company:  ORCL\n",
            "summary 2 tables\n",
            "summary 16 Columns\n",
            "analysis 6 tables\n",
            "analysis 120 Columns\n",
            "Column mismatch for company:  ORCL  Ignoring...\n",
            "\n",
            "Company:  IBM\n",
            "summary 2 tables\n",
            "summary 16 Columns\n",
            "analysis 6 tables\n",
            "analysis 120 Columns\n",
            "intersections:  (0,) (0,)\n",
            "\n",
            "Company:  FB\n",
            "summary 2 tables\n",
            "summary 16 Columns\n",
            "analysis 6 tables\n",
            "analysis 120 Columns\n",
            "intersections:  (0,) (0,)\n",
            "\n",
            "Company:  TWTR\n",
            "summary 2 tables\n",
            "summary 16 Columns\n",
            "analysis 6 tables\n",
            "analysis 120 Columns\n",
            "intersections:  (0,) (0,)\n",
            "\n",
            "Company:  AMZN\n",
            "summary 2 tables\n",
            "summary 16 Columns\n",
            "analysis 6 tables\n",
            "analysis 120 Columns\n",
            "intersections:  (0,) (0,)\n",
            "\n",
            "Company:  SNAP\n",
            "summary 2 tables\n",
            "summary 16 Columns\n",
            "analysis 6 tables\n",
            "analysis 120 Columns\n",
            "intersections:  (0,) (0,)\n",
            "\n",
            "Company:  SCHW\n",
            "summary 2 tables\n",
            "summary 16 Columns\n",
            "analysis 6 tables\n",
            "analysis 120 Columns\n",
            "intersections:  (0,) (0,)\n",
            "\n",
            "Company:  ETFC\n",
            "summary 2 tables\n",
            "summary 16 Columns\n",
            "analysis 6 tables\n",
            "analysis 120 Columns\n",
            "intersections:  (0,) (0,)\n",
            "\n",
            "Company:  AMTD\n",
            "summary 2 tables\n",
            "summary 16 Columns\n",
            "analysis 6 tables\n",
            "analysis 120 Columns\n",
            "intersections:  (0,) (0,)\n",
            "Final Data:  (22, 136)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "88DDkNh_LDXD",
        "colab_type": "code",
        "outputId": "54b657fa-91f4-4589-c0c1-42d7a6a8d5a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "towriteCmpList = []\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('drive')\n",
        "\n",
        "#https://finance.yahoo.com/quote/%5EIXIC/components?p=%5EIXIC\n",
        "\n",
        "items = ['/financials']\n",
        "urlPre = 'https://www.marketwatch.com/investing/stock/'\n",
        "\n",
        "columns = None\n",
        "\n",
        "\n",
        "final_df = pd.DataFrame()\n",
        "\n",
        "for cmp in cmpList:\n",
        "  cmp_df_list = []\n",
        "  print('\\nCompany: ', cmp)\n",
        "  \n",
        "  for item in items:\n",
        "    url = urlPre + cmp + item\n",
        "    dataframe_list = parse_url(url, cmp)\n",
        "    \n",
        "    if item is '':\n",
        "      name = 'summary'\n",
        "    else:\n",
        "      name = item[1:len(item)]\n",
        "    \n",
        "    print(name, len(dataframe_list), 'tables')\n",
        "    \n",
        "    count = 1\n",
        "    \n",
        "    item_df = pd.DataFrame()\n",
        "    \n",
        "    for df in dataframe_list:\n",
        "    \n",
        "      # Summary (2), Analysis (6)\n",
        "      \n",
        "      if item is \"\":\n",
        "        df = df.transpose()\n",
        "        item_df = pd.concat([item_df, df], axis = 1, ignore_index = True)\n",
        "        \n",
        "        \n",
        "        \n",
        "      if item == '/financials':\n",
        "        df.set_index(df.columns[0], inplace=True)\n",
        "        df = df.replace({pd.np.nan: None})\n",
        "        df = df.unstack().to_frame().sort_index(level=1).T\n",
        "        df.columns = df.columns.map(\"_\".join)\n",
        "        item_df = pd.concat([item_df, df], axis = 1)\n",
        "     \n",
        "    \n",
        "    if item is \"\":\n",
        "      new_header = item_df.iloc[0] #grab the first row for the header\n",
        "#       print(item_df)\n",
        "      item_df.columns = new_header #set the header row as the df header\n",
        "#       print(item_df)\n",
        "      item_df = item_df[1:] #take the data less the header row\n",
        "#       print(item_df)\n",
        "#       print(new_header)\n",
        "      item_df.reset_index(inplace=True, drop=True)\n",
        "     \n",
        "      \n",
        "    #print(item_df)\n",
        "    print(name, item_df.shape[1], 'Columns')\n",
        "    cmp_df_list.append(item_df)\n",
        "    \n",
        "#     filename = cmp + '_' + name + '.csv'\n",
        "#     item_df.to_csv(filename, index = False)\n",
        "#     !cp $filename drive/My\\ Drive/Isenberg/\n",
        "  \n",
        "  \n",
        "  \n",
        "  cmp_df = pd.DataFrame()\n",
        "  for df in cmp_df_list:\n",
        "    cmp_df = pd.concat([cmp_df,df], axis = 1)\n",
        "  \n",
        "  # Causes problem when company name is \"F\" and it gets replaced everywhere in the column names. Better to do in parse_url\n",
        "  # cmp_df.columns = cmp_df.columns.str.replace(cmp, \"cmp\")\n",
        "  \n",
        "  if columns == None:\n",
        "    columns = cmp_df.columns.tolist()\n",
        " \n",
        "  #cmp_df.sort_index(axis=1, inplace=True) # not required if string replace done at parsing time\n",
        "  \n",
        "  if (final_df.shape[0] != 0 and final_df.columns.equals(cmp_df.columns) == False ):\n",
        "    # except when final_df is empty. This should return always True. Else column mistmatch (ignore this company)\n",
        "    print('Column mismatch for company: ', cmp, ' Ignoring...')\n",
        "    continue\n",
        "    # MSFT: has current year (2020): typo\n",
        "    # ADBE: has different dates\n",
        "  else:\n",
        "    towriteCmpList.append(cmp)\n",
        "  \n",
        "  #print('intersections: ', cmp_df.columns.difference(final_df.columns).shape, final_df.columns.difference(cmp_df.columns).shape) #should always print 0\n",
        "  \n",
        "  final_df = pd.concat([final_df, cmp_df], ignore_index = True)\n",
        "\n",
        "final_df['company'] = towriteCmpList  \n",
        "final_df = final_df.set_index('company')\n",
        "print('Final Data: ',final_df.shape)\n",
        "\n",
        "filename = 'MarketWatchData.xlsx'\n",
        "final_df.to_excel(filename)\n",
        "!cp $filename drive/My\\ Drive/Isenberg/"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at drive; to attempt to forcibly remount, call drive.mount(\"drive\", force_remount=True).\n",
            "\n",
            "Company:  TSLA\n",
            "financials 2 tables\n",
            "financials 342 Columns\n",
            "\n",
            "Company:  AAPL\n",
            "financials 2 tables\n",
            "financials 342 Columns\n",
            "\n",
            "Company:  NFLX\n",
            "financials 2 tables\n",
            "financials 342 Columns\n",
            "\n",
            "Company:  GM\n",
            "financials 2 tables\n",
            "financials 342 Columns\n",
            "\n",
            "Company:  F\n",
            "financials 2 tables\n",
            "financials 342 Columns\n",
            "\n",
            "Company:  FCAU\n",
            "financials 2 tables\n",
            "financials 342 Columns\n",
            "\n",
            "Company:  PCAR\n",
            "financials 2 tables\n",
            "financials 342 Columns\n",
            "\n",
            "Company:  MRK\n",
            "financials 2 tables\n",
            "financials 342 Columns\n",
            "\n",
            "Company:  PFE\n",
            "financials 2 tables\n",
            "financials 342 Columns\n",
            "\n",
            "Company:  JNJ\n",
            "financials 2 tables\n",
            "financials 342 Columns\n",
            "\n",
            "Company:  BMY\n",
            "financials 2 tables\n",
            "financials 342 Columns\n",
            "\n",
            "Company:  QCOM\n",
            "financials 2 tables\n",
            "financials 342 Columns\n",
            "\n",
            "Company:  MSFT\n",
            "financials 2 tables\n",
            "financials 342 Columns\n",
            "Column mismatch for company:  MSFT  Ignoring...\n",
            "\n",
            "Company:  ADBE\n",
            "financials 2 tables\n",
            "financials 342 Columns\n",
            "\n",
            "Company:  INTC\n",
            "financials 2 tables\n",
            "financials 342 Columns\n",
            "\n",
            "Company:  GOOGL\n",
            "financials 2 tables\n",
            "financials 342 Columns\n",
            "\n",
            "Company:  CRM\n",
            "financials 2 tables\n",
            "financials 342 Columns\n",
            "Column mismatch for company:  CRM  Ignoring...\n",
            "\n",
            "Company:  ORCL\n",
            "financials 2 tables\n",
            "financials 342 Columns\n",
            "Column mismatch for company:  ORCL  Ignoring...\n",
            "\n",
            "Company:  IBM\n",
            "financials 2 tables\n",
            "financials 342 Columns\n",
            "\n",
            "Company:  FB\n",
            "financials 2 tables\n",
            "financials 342 Columns\n",
            "\n",
            "Company:  TWTR\n",
            "financials 2 tables\n",
            "financials 342 Columns\n",
            "\n",
            "Company:  AMZN\n",
            "financials 2 tables\n",
            "financials 342 Columns\n",
            "\n",
            "Company:  SCHW\n",
            "financials 2 tables\n",
            "financials 282 Columns\n",
            "Column mismatch for company:  SCHW  Ignoring...\n",
            "\n",
            "Company:  ETFC\n",
            "financials 2 tables\n",
            "financials 282 Columns\n",
            "Column mismatch for company:  ETFC  Ignoring...\n",
            "\n",
            "Company:  AMTD\n",
            "financials 2 tables\n",
            "financials 282 Columns\n",
            "Column mismatch for company:  AMTD  Ignoring...\n",
            "Final Data:  (19, 342)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PZdeeGg58KZk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# #listdf = parse_url(\"https://www.marketwatch.com/investing/stock/aapl/financials\")\n",
        "# listf = parse_url(\"https://old.nasdaq.com/symbol/aapl/financials?query=balance-sheet\")\n",
        "# for df in listdf:\n",
        "#   print(df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nxbem-Ag9NsZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def getSummaryData(url):\n",
        "  response = requests.get(url, verify=False)\n",
        "  print (\"Parsing %s\"%(url))\n",
        "  sleep(4)\n",
        "  parser = html.fromstring(response.text)\n",
        "  summary_table = parser.xpath('//div[contains(@data-test,\"summary-table\")]//tr')\n",
        "  summary_data = OrderedDict()\n",
        "  try:\n",
        "    for table_data in summary_table:\n",
        "      raw_table_key = table_data.xpath('.//td[contains(@class,\"C($primaryColor)\")]//text()')\n",
        "      raw_table_value = table_data.xpath('.//td[contains(@class,\"Ta(end)\")]//text()')\n",
        "      table_key = ''.join(raw_table_key).strip()\n",
        "      table_value = ''.join(raw_table_value).strip()\n",
        "      summary_data.update({table_key:table_value})\n",
        "    return summary_data\n",
        "  \n",
        "  except:\n",
        "    print (\"Failed to parse json response\")\n",
        "    return {\"error\":\"Failed to parse json response\"}\n",
        "  \n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-E9hrQmw9SjZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def getFinanceData(url):\n",
        "  response = requests.get(url, verify=False)\n",
        "  print (\"Parsing %s\"%(url))\n",
        "  sleep(4)\n",
        "  parser = html.fromstring(response.text)\n",
        "  summary_table = parser.xpath('//div[contains(@data-test,\"fin-row\")]')\n",
        "  print(len(summary_table))\n",
        "  summary_data = pd.DataFrame()\n",
        "\n",
        "  for table_data in summary_table:\n",
        "    raw_table_key = table_data.xpath('.//span[contains(@class,\"Va(m)\")]//text()')\n",
        "\n",
        "    raw_table_value = table_data.xpath('.//span[not(contains(@class,\"Va(m)\"))]//text()')\n",
        "\n",
        "    print('table_key', raw_table_key)\n",
        "    print('table_value', raw_table_value)\n",
        "    \n",
        "  return summary_data\n",
        "    \n",
        "# empty cells, heirarchical cells\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h3hJEXvD9UWs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# financeUrl = \"https://finance.yahoo.com/quote/TSLA/financials?p=TSLA\"\n",
        "# scrappedData = getFinanceData(financeUrl)\n",
        "# print(scrappedData)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}