{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "crawlYahooFinance.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "BdOwvJngGoXs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import bs4 as bs\n",
        "import urllib.request\n",
        "import pandas as pd\n",
        "from time import sleep\n",
        "from lxml import html  \n",
        "import requests\n",
        "from time import sleep\n",
        "import json\n",
        "import argparse\n",
        "from collections import OrderedDict\n",
        "import lxml.html as lh\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ok5NicSRpaNJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def getSummaryData(url):\n",
        "  response = requests.get(url, verify=False)\n",
        "  print (\"Parsing %s\"%(url))\n",
        "  sleep(4)\n",
        "  parser = html.fromstring(response.text)\n",
        "  summary_table = parser.xpath('//div[contains(@data-test,\"summary-table\")]//tr')\n",
        "  summary_data = OrderedDict()\n",
        "  try:\n",
        "    for table_data in summary_table:\n",
        "      raw_table_key = table_data.xpath('.//td[contains(@class,\"C($primaryColor)\")]//text()')\n",
        "      raw_table_value = table_data.xpath('.//td[contains(@class,\"Ta(end)\")]//text()')\n",
        "      table_key = ''.join(raw_table_key).strip()\n",
        "      table_value = ''.join(raw_table_value).strip()\n",
        "      summary_data.update({table_key:table_value})\n",
        "    return summary_data\n",
        "  \n",
        "  except:\n",
        "    print (\"Failed to parse json response\")\n",
        "    return {\"error\":\"Failed to parse json response\"}\n",
        "  \n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UeqmNqHT1A4H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def getFinanceData(url):\n",
        "  response = requests.get(url, verify=False)\n",
        "  print (\"Parsing %s\"%(url))\n",
        "  sleep(4)\n",
        "  parser = html.fromstring(response.text)\n",
        "  summary_table = parser.xpath('//div[contains(@data-test,\"fin-row\")]')\n",
        "  print(len(summary_table))\n",
        "  summary_data = pd.DataFrame()\n",
        "\n",
        "  for table_data in summary_table:\n",
        "    raw_table_key = table_data.xpath('.//span[contains(@class,\"Va(m)\")]//text()')\n",
        "\n",
        "    raw_table_value = table_data.xpath('.//span[not(contains(@class,\"Va(m)\"))]//text()')\n",
        "\n",
        "    print('table_key', raw_table_key)\n",
        "    print('table_value', raw_table_value)\n",
        "    \n",
        "  return summary_data\n",
        "    \n",
        "# empty cells, heirarchical cells\n",
        "  \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4kkSF_pKSfLo",
        "colab_type": "code",
        "outputId": "ff73ef5f-770c-4a81-d0c1-f4d28d93ba7f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 904
        }
      },
      "source": [
        "financeUrl = \"https://finance.yahoo.com/quote/TSLA/financials?p=TSLA\"\n",
        "scrappedData = getFinanceData(financeUrl)\n",
        "print(scrappedData)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/urllib3/connectionpool.py:847: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
            "  InsecureRequestWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Parsing https://finance.yahoo.com/quote/TSLA/financials?p=TSLA\n",
            "22\n",
            "table_key ['Total Revenue']\n",
            "table_value ['24,941,426', '21,461,268', '11,758,751', '7,000,132', '4,046,024']\n",
            "table_key ['Cost of Revenue']\n",
            "table_value ['20,488,072', '17,419,247', '9,536,264', '5,400,875', '3,122,521']\n",
            "table_key ['Gross Profit']\n",
            "table_value ['4,453,354', '4,042,021', '2,222,487', '1,599,257', '923,503']\n",
            "table_key ['Operating Expenses', 'Research Development', 'Selling General and Administrative', 'Total Operating Expenses']\n",
            "table_value ['1,371,217', '1,460,370', '1,378,073', '834,408', '717,900', '2,748,518', '2,834,491', '2,476,500', '1,432,189', '922,232', '4,119,735', '4,294,861', '3,854,573', '2,266,597', '1,640,132']\n",
            "table_key ['Research Development']\n",
            "table_value ['1,371,217', '1,460,370', '1,378,073', '834,408', '717,900']\n",
            "table_key ['Selling General and Administrative']\n",
            "table_value ['2,748,518', '2,834,491', '2,476,500', '1,432,189', '922,232']\n",
            "table_key ['Total Operating Expenses']\n",
            "table_value ['4,119,735', '4,294,861', '3,854,573', '2,266,597', '1,640,132']\n",
            "table_key ['Operating Income or Loss']\n",
            "table_value ['333,619', '-252,840', '-1,632,086', '-667,340', '-716,629']\n",
            "table_key ['Interest Expense']\n",
            "table_value ['679,375', '663,071', '471,259', '198,810', '118,851']\n",
            "table_key ['Total Other Income/Expenses Net']\n",
            "table_value ['-198,950', '-113,367', '-125,373', '111,272', '-41,652']\n",
            "table_key ['Income Before Tax']\n",
            "table_value ['-511,327', '-1,004,745', '-2,209,032', '-746,348', '-875,624']\n",
            "table_key ['Income Tax Expense']\n",
            "table_value ['80,829', '57,837', '31,546', '26,698', '13,039']\n",
            "table_key ['Income from Continuing Operations']\n",
            "table_value ['-592,156', '-1,062,582', '-2,240,578', '-773,046', '-888,663']\n",
            "table_key ['Net Income']\n",
            "table_value ['-659,470', '-976,091', '-1,961,400', '-674,914', '-888,663']\n",
            "table_key ['Net Income available to common shareholders']\n",
            "table_value ['-659,470', '-976,091', '-1,961,400', '-674,914', '-888,663']\n",
            "table_key ['Reported EPS', 'Basic', 'Diluted']\n",
            "table_value []\n",
            "table_key ['Basic']\n",
            "table_value []\n",
            "table_key ['Diluted']\n",
            "table_value []\n",
            "table_key ['Weighted average shares outstanding', 'Basic', 'Diluted']\n",
            "table_value ['170,525', '165,758', '144,212', '128,202', '170,525', '165,758', '144,212', '128,202']\n",
            "table_key ['Basic']\n",
            "table_value ['170,525', '165,758', '144,212', '128,202']\n",
            "table_key ['Diluted']\n",
            "table_value ['170,525', '165,758', '144,212', '128,202']\n",
            "table_key ['EBITDA']\n",
            "table_value ['1,559,376', '-101,770', '399,561', '-756,773']\n",
            "Empty DataFrame\n",
            "Columns: []\n",
            "Index: []\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LpC5ggz-twKQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def parse_url(url):\n",
        "  response = requests.get(url)\n",
        "  soup = bs.BeautifulSoup(response.text, 'lxml')\n",
        "  \n",
        "  listdf = []\n",
        "  \n",
        "  for table in soup.find_all('table'):\n",
        "    listdf.append(parse_html_table(table))\n",
        "  \n",
        "  return listdf\n",
        "    \n",
        "def parse_html_table(table):\n",
        "  n_columns = 0\n",
        "  n_rows=0\n",
        "  column_names = []\n",
        "\n",
        "  # Find number of rows and columns\n",
        "  # we also find the column titles if we can\n",
        "  for row in table.find_all('tr'):\n",
        "\n",
        "      # Determine the number of rows in the table\n",
        "      td_tags = row.find_all('td')\n",
        "      if len(td_tags) > 0:\n",
        "          n_rows+=1\n",
        "          if n_columns == 0:\n",
        "              # Set the number of columns for our table\n",
        "              n_columns = len(td_tags)\n",
        "\n",
        "      # Handle column names if we find them\n",
        "      th_tags = row.find_all('th') \n",
        "      if len(th_tags) > 0 and len(column_names) == 0:\n",
        "          for th in th_tags:\n",
        "              column_names.append(th.get_text())\n",
        "  \n",
        "  # Safeguard on Column Titles\n",
        "  if len(column_names) > 0 and len(column_names) != n_columns:\n",
        "      raise Exception(\"Column titles do not match the number of columns\")\n",
        "\n",
        "  columns = column_names if len(column_names) > 0 else range(0,n_columns)\n",
        "  df = pd.DataFrame(columns = columns,\n",
        "                    index= range(0,n_rows))\n",
        "  row_marker = 0\n",
        "  for row in table.find_all('tr'):\n",
        "      column_marker = 0\n",
        "      columns = row.find_all('td')\n",
        "      for column in columns:\n",
        "          df.iat[row_marker,column_marker] = column.get_text()\n",
        "          column_marker += 1\n",
        "      if len(columns) > 0:\n",
        "          row_marker += 1\n",
        "\n",
        "  # Convert to float if possible\n",
        "  for col in df:\n",
        "      try:\n",
        "          df[col] = df[col].astype(float)\n",
        "      except ValueError:\n",
        "          pass\n",
        "\n",
        "  return df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fPodJIKYG2UA",
        "colab_type": "code",
        "outputId": "3ed1d873-d462-4a6e-af84-1b26030ed7a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 528
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('drive')\n",
        "cmpList = ['TSLA', 'AAPL', 'NFLX']\n",
        "#https://finance.yahoo.com/quote/%5EIXIC/components?p=%5EIXIC\n",
        "\n",
        "items = ['', '/analysis']\n",
        "urlPre = 'https://finance.yahoo.com/quote/'\n",
        "urlSuf = '?p='\n",
        "\n",
        "columns = None\n",
        "\n",
        "#scrappedData = getSummaryData(summaryUrl)\n",
        "# response = requests.get(financeUrl, verify=False)\n",
        "# soup = bs.BeautifulSoup(response.text)\n",
        "# print(soup.prettify())\n",
        "final_df = pd.DataFrame()\n",
        "\n",
        "for cmp in cmpList:\n",
        "  cmp_df_list = []\n",
        "  print('\\nCompany: ', cmp)\n",
        "  \n",
        "  for item in items:\n",
        "    url = urlPre + cmp + item + urlSuf + cmp\n",
        "    dataframe_list = parse_url(url)\n",
        "    \n",
        "    if item is '':\n",
        "      name = 'summary'\n",
        "    else:\n",
        "      name = item[1:len(item)]\n",
        "    \n",
        "    print(name, len(dataframe_list), 'tables')\n",
        "    \n",
        "    count = 1\n",
        "    \n",
        "    item_df = pd.DataFrame()\n",
        "    \n",
        "    for df in dataframe_list:\n",
        "    \n",
        "      # Summary (2), Analysis (6)\n",
        "      \n",
        "      if item is \"\":\n",
        "        df = df.transpose()\n",
        "        item_df = pd.concat([item_df, df], axis = 1, ignore_index = True)\n",
        "        \n",
        "        \n",
        "        \n",
        "      if item == '/analysis':\n",
        "        df.set_index(df.columns[0], inplace=True)\n",
        "        df = df.replace({pd.np.nan: None})\n",
        "        df = df.unstack().to_frame().sort_index(level=1).T\n",
        "        df.columns = df.columns.map(\"_\".join)\n",
        "        item_df = pd.concat([item_df, df], axis = 1)\n",
        "     \n",
        "    \n",
        "    if item is \"\":\n",
        "      new_header = item_df.iloc[0] #grab the first row for the header\n",
        "#       print(item_df)\n",
        "      item_df.columns = new_header #set the header row as the df header\n",
        "#       print(item_df)\n",
        "      item_df = item_df[1:] #take the data less the header row\n",
        "#       print(item_df)\n",
        "#       print(new_header)\n",
        "      item_df.reset_index(inplace=True, drop=True)\n",
        "     \n",
        "      \n",
        "    #print(item_df)\n",
        "    print(name, item_df.shape[1], 'Columns')\n",
        "    cmp_df_list.append(item_df)\n",
        "    \n",
        "#     filename = cmp + '_' + name + '.csv'\n",
        "#     item_df.to_csv(filename, index = False)\n",
        "#     !cp $filename drive/My\\ Drive/Isenberg/\n",
        "  \n",
        "  \n",
        "  \n",
        "  cmp_df = pd.DataFrame()\n",
        "  for df in cmp_df_list:\n",
        "    cmp_df = pd.concat([cmp_df,df], axis = 1)\n",
        "  \n",
        "  cmp_df.columns = cmp_df.columns.str.replace(cmp, \"cmp\")\n",
        "  \n",
        "  if columns == None:\n",
        "    columns = cmp_df.columns.tolist()\n",
        " \n",
        "  cmp_df.sort_index(axis=1, inplace=True)\n",
        "\n",
        "  final_df = pd.concat([final_df, cmp_df], ignore_index = True)\n",
        "\n",
        "final_df['company'] = cmpList  \n",
        "final_df = final_df.set_index('company')\n",
        "print('Final Data: ',final_df.shape)\n",
        "\n",
        "filename = 'YahooData.csv'\n",
        "final_df.to_csv(filename)\n",
        "!cp $filename drive/My\\ Drive/Isenberg/"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    729\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 730\u001b[0;31m                 \u001b[0mident\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdin_socket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    731\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/jupyter_client/session.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, socket, mode, content, copy)\u001b[0m\n\u001b[1;32m    802\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 803\u001b[0;31m             \u001b[0mmsg_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_multipart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    804\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mzmq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZMQError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36mrecv_multipart\u001b[0;34m(self, flags, copy, track)\u001b[0m\n\u001b[1;32m    465\u001b[0m         \"\"\"\n\u001b[0;32m--> 466\u001b[0;31m         \u001b[0mparts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    467\u001b[0m         \u001b[0;31m# have first part already, only loop while more to receive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._recv_copy\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-540862568bb2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mcmpList\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'TSLA'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'AAPL'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'NFLX'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#https://finance.yahoo.com/quote/%5EIXIC/components?p=%5EIXIC\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms)\u001b[0m\n\u001b[1;32m    223\u001b[0m       \u001b[0mauth_prompt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'\\nEnter your authorization code:\\n'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfifo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfifo_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 225\u001b[0;31m         \u001b[0mfifo_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_getpass\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetpass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mauth_prompt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    226\u001b[0m       \u001b[0mwrote_to_fifo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mwrote_to_fifo\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mgetpass\u001b[0;34m(self, prompt, stream)\u001b[0m\n\u001b[1;32m    686\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m             \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m         )\n\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    733\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    734\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 735\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    736\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    737\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QBTtVrewIIfx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# #listdf = parse_url(\"https://www.marketwatch.com/investing/stock/aapl/financials\")\n",
        "# listf = parse_url(\"https://old.nasdaq.com/symbol/aapl/financials?query=balance-sheet\")\n",
        "# for df in listdf:\n",
        "#   print(df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "88DDkNh_LDXD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "f62b75f0-8f8b-4636-fa6d-9eb61ce66109"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('drive')\n",
        "cmpList = ['TSLA', 'AAPL', 'NFLX']\n",
        "#https://finance.yahoo.com/quote/%5EIXIC/components?p=%5EIXIC\n",
        "\n",
        "items = ['/financials']\n",
        "urlPre = 'https://www.marketwatch.com/investing/stock/'\n",
        "\n",
        "columns = None\n",
        "\n",
        "\n",
        "final_df = pd.DataFrame()\n",
        "\n",
        "for cmp in cmpList:\n",
        "  cmp_df_list = []\n",
        "  print('\\nCompany: ', cmp)\n",
        "  \n",
        "  for item in items:\n",
        "    url = urlPre + cmp + item\n",
        "    dataframe_list = parse_url(url)\n",
        "    \n",
        "    if item is '':\n",
        "      name = 'summary'\n",
        "    else:\n",
        "      name = item[1:len(item)]\n",
        "    \n",
        "    print(name, len(dataframe_list), 'tables')\n",
        "    \n",
        "    count = 1\n",
        "    \n",
        "    item_df = pd.DataFrame()\n",
        "    \n",
        "    for df in dataframe_list:\n",
        "    \n",
        "      if item is \"\":\n",
        "        df = df.transpose()\n",
        "        item_df = pd.concat([item_df, df], axis = 1, ignore_index = True)\n",
        "        \n",
        "        \n",
        "        \n",
        "      if item == '/financials':\n",
        "        df.set_index(df.columns[0], inplace=True)\n",
        "        df = df.replace({pd.np.nan: None})\n",
        "        df = df.unstack().to_frame().sort_index(level=1).T\n",
        "        df.columns = df.columns.map(\"_\".join)\n",
        "        item_df = pd.concat([item_df, df], axis = 1)\n",
        "     \n",
        "    \n",
        "    if item is \"\":\n",
        "      new_header = item_df.iloc[0] #grab the first row for the header\n",
        "#       print(item_df)\n",
        "      item_df.columns = new_header #set the header row as the df header\n",
        "#       print(item_df)\n",
        "      item_df = item_df[1:] #take the data less the header row\n",
        "#       print(item_df)\n",
        "#       print(new_header)\n",
        "      item_df.reset_index(inplace=True, drop=True)\n",
        "     \n",
        "      \n",
        "    #print(item_df)\n",
        "    print(name, item_df.shape[1], 'Columns')\n",
        "    cmp_df_list.append(item_df)\n",
        "    \n",
        "#     filename = cmp + '_' + name + '.csv'\n",
        "#     item_df.to_csv(filename, index = False)\n",
        "#     !cp $filename drive/My\\ Drive/Isenberg/\n",
        "  \n",
        "  \n",
        "  \n",
        "  cmp_df = pd.DataFrame()\n",
        "  for df in cmp_df_list:\n",
        "    cmp_df = pd.concat([cmp_df,df], axis = 1)\n",
        "  \n",
        "  cmp_df.columns = cmp_df.columns.str.replace(cmp, \"cmp\")\n",
        "  \n",
        "  if columns == None:\n",
        "    columns = cmp_df.columns.tolist()\n",
        " \n",
        "  cmp_df.sort_index(axis=1, inplace=True)\n",
        "\n",
        "  final_df = pd.concat([final_df, cmp_df], ignore_index = True)\n",
        "\n",
        "final_df['company'] = cmpList  \n",
        "final_df = final_df.set_index('company')\n",
        "print('Final Data: ',final_df.shape)\n",
        "\n",
        "filename = 'MarketWatchData.xlsx'\n",
        "final_df.to_excel(filename)\n",
        "!cp $filename drive/My\\ Drive/Isenberg/"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at drive; to attempt to forcibly remount, call drive.mount(\"drive\", force_remount=True).\n",
            "\n",
            "Company:  TSLA\n",
            "financials 2 tables\n",
            "financials 342 Columns\n",
            "\n",
            "Company:  AAPL\n",
            "financials 2 tables\n",
            "financials 342 Columns\n",
            "\n",
            "Company:  NFLX\n",
            "financials 2 tables\n",
            "financials 342 Columns\n",
            "Final Data:  (3, 342)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-KkJ-a5sLEtx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}