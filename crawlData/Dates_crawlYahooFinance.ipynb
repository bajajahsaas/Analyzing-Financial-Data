{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Dates_crawlYahooFinance.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "BdOwvJngGoXs",
        "colab_type": "code",
        "outputId": "a4f84900-570c-4f82-cb66-8d9feb789871",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import bs4 as bs\n",
        "import urllib.request\n",
        "import pandas as pd\n",
        "from time import sleep\n",
        "from lxml import html  \n",
        "import requests\n",
        "import json\n",
        "import argparse\n",
        "from collections import OrderedDict\n",
        "import lxml.html as lh\n",
        "import copy\n",
        "import pandas as pd\n",
        "import urllib3\n",
        "!pip install --upgrade -q pygsheets\n",
        "!pip install --upgrade -q gspread\n",
        "from google.colab import drive\n",
        "drive.mount('drive')\n",
        "import gspread\n",
        "import pygsheets"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at drive; to attempt to forcibly remount, call drive.mount(\"drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LwCrnc2uiuYn",
        "colab_type": "code",
        "outputId": "ea48daa6-f6f0-4136-f173-87ee73ed019f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "auth.authenticate_user()\n",
        "gc = gspread.authorize(GoogleCredentials.get_application_default())\n",
        "worksheet = gc.open('TICS').sheet1\n",
        "\n",
        "# get_all_values gives a list of rows.\n",
        "rows = worksheet.get_all_values()\n",
        "\n",
        "# Convert to a DataFrame and render.\n",
        "import pandas as pd\n",
        "data = pd.DataFrame.from_records(rows, index = None)\n",
        "cmpList = data[data.columns[0]].astype(str).values.tolist()\n",
        "print('Number of tickets', len(cmpList))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of tickets 100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rctUXUkK6uR0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sleep_val = 3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NFI2zPu-QKRV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# for parsing yahoo finance data\n",
        "#items = ['/financials?p=', '/balance-sheet?p=', '/cash-flow?p=']\n",
        "\n",
        "financialslen = 5\n",
        "balancesheetlen = 4\n",
        "cashflowlen = 5\n",
        "\n",
        "def getFinanceData(url, name):\n",
        "  global financialslen\n",
        "  global balancesheetlen\n",
        "  global cashflowlen\n",
        "  if name  == \"financials\":\n",
        "    dates_len = financialslen\n",
        "  elif name  == \"balance-sheet\":\n",
        "    dates_len = balancesheetlen\n",
        "  elif name  == \"cash-flow\":\n",
        "    dates_len = cashflowlen\n",
        "  try:\n",
        "    #urllib.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n",
        "    response = requests.get(url, verify=False)\n",
        "    sleep(sleep_val)\n",
        "    parser = html.fromstring(response.text)\n",
        "    finance_table = parser.xpath('//div[contains(@class,\"Pos(r)\")]')\n",
        "    keys = []\n",
        "    values = []\n",
        "    \n",
        "    columnLen = 0 \n",
        "    for table_data in finance_table:\n",
        "      raw_table_key = table_data.xpath('.//span//text()')\n",
        "      if len(raw_table_key) > 1 and raw_table_key[0] == \"Breakdown\":\n",
        "        dates_df = pd.DataFrame(raw_table_key[1: dates_len + 1])\n",
        "        return dates_df.T\n",
        "    return \n",
        "  except:\n",
        "    return pd.DataFrame()\n",
        "      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N43dmWdYQVzf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def writeDatesYahooFinancial(): \n",
        "  # Parsing data from yahoo (financials)\n",
        "  print(\"\\nWriting Yahoo Financials\")\n",
        "  towriteCmpList = []\n",
        "  ignored_cmp = []\n",
        "  finalcolsize = 14\n",
        "\n",
        "  items = ['/financials?p=', '/balance-sheet?p=', '/cash-flow?p=']\n",
        "  urlPre = 'https://finance.yahoo.com/quote/'\n",
        "\n",
        "  columns = None\n",
        "\n",
        "\n",
        "  final_df = pd.DataFrame()\n",
        "\n",
        "  for cmp in cmpList:\n",
        "    cmp_df_list = []\n",
        "    print('\\nCompany: ', cmp)\n",
        "    \n",
        "    for item in items:\n",
        "      url = urlPre + cmp + item + cmp\n",
        "      # dataframe_list = parse_url(url, cmp)\n",
        "    \n",
        "      name = item[1:len(item) - 3]\n",
        "      count = 1\n",
        "      item_df = getFinanceData(url, name)\n",
        "      cmp_df_list.append(item_df)\n",
        "      \n",
        "  #     filename = cmp + '_' + name + '.csv'\n",
        "  #     item_df.to_csv(filename, index = False)\n",
        "  #     !cp $filename drive/My\\ Drive/Research/AB/\n",
        "    \n",
        "    \n",
        "  \n",
        "    cmp_df = pd.DataFrame()\n",
        "    for df in cmp_df_list:\n",
        "      cmp_df = pd.concat([cmp_df,df], axis = 1)\n",
        "    \n",
        "    # Causes problem when company name is \"F\" and it gets replaced everywhere in the column names. Better to do in parse_url\n",
        "    # cmp_df.columns = cmp_df.columns.str.replace(cmp, \"cmp\")\n",
        "    \n",
        "    if columns == None:\n",
        "      columns = cmp_df.columns.tolist()\n",
        "  \n",
        "    #cmp_df.sort_index(axis=1, inplace=True) # not required if string replace done at parsing time\n",
        "    \n",
        "    \n",
        "    if cmp_df.shape[1] != finalcolsize:\n",
        "      # if first cmp, size of columns should match else exact columns match should return always True. Else column mistmatch (ignore this company)\n",
        "      print('Column mismatch for company: ', cmp, ' Ignoring...')\n",
        "      #print('differences: ', cmp_df.columns.difference(final_df.columns), final_df.columns.difference(cmp_df.columns)) #should always print 0\n",
        "      ignored_cmp.append(cmp)\n",
        "      continue\n",
        "    \n",
        "    towriteCmpList.append(cmp)\n",
        "    \n",
        "    final_df = pd.concat([final_df, cmp_df], ignore_index = True)\n",
        "\n",
        "\n",
        "  final_df['company'] = towriteCmpList  \n",
        "  final_df = final_df.set_index('company')\n",
        "  print('Final Data: ',final_df.shape)\n",
        " \n",
        "  filename = 'YahooFinancesDates.xlsx'\n",
        "  final_df.to_excel(filename)\n",
        "  !cp $filename drive/My\\ Drive/Research/AB/\n",
        "\n",
        "  if len(ignored_cmp) > 0:\n",
        "    ignored_csv = pd.DataFrame(ignored_cmp)\n",
        "    ignored_filename = 'YahooFinancesDates_ignoredcmp.xlsx'\n",
        "    ignored_csv.to_excel(ignored_filename, index=\"False\")\n",
        "    !cp $ignored_filename drive/My\\ Drive/Research/AB/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sxNcFJz9aEqg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "8d788951-f1a6-482e-f742-93f74518fe69"
      },
      "source": [
        "writeDatesYahooFinancial()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Writing Yahoo Financials\n",
            "\n",
            "Company:  A\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/urllib3/connectionpool.py:847: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
            "  InsecureRequestWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/urllib3/connectionpool.py:847: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
            "  InsecureRequestWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/urllib3/connectionpool.py:847: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
            "  InsecureRequestWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YMk9_4Oe0DyI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}